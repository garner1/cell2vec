{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndarray\n",
    "\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse import csc_matrix,coo_matrix\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN, KMeans, AffinityPropagation, MeanShift\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import kmapper as km\n",
    "from kmapper.cover import Cover\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "import networkx as nx\n",
    "from community import best_partition # this is not part of networkx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax    \n",
    "def embedding(data,dim):\n",
    "    projection = mapper.fit_transform(data, projection=umap.UMAP(n_components=dim, n_neighbors=200, \n",
    "                                             a=None, angular_rp_forest=False, b=None, init='spectral',\n",
    "                                           learning_rate=1.0, local_connectivity=1.0, metric='euclidean',\n",
    "                                           metric_kwds=None, min_dist=0.1, n_epochs=500,\n",
    "                                           negative_sample_rate=10, random_state=47,\n",
    "                                           repulsion_strength=1.0, set_op_mix_ratio=0.5, spread=0.25,\n",
    "                                           target_metric='categorical', target_metric_kwds=None,\n",
    "                                           target_n_neighbors=-1, target_weight=0.5, transform_queue_size=10.0,\n",
    "                                           transform_seed=42, verbose=False))\n",
    "    return projection\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax    \n",
    "\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "\n",
    "def rotate_image(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2] # image shape has 3 dimensions\n",
    "    image_center = (width/2, height/2) # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "\n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0,0]) \n",
    "    abs_sin = abs(rotation_mat[0,1])\n",
    "\n",
    "    # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h))\n",
    "    return rotated_mat\n",
    "\n",
    "import math\n",
    "\n",
    "def round_up_to_even(f):\n",
    "    return int(math.ceil(f / 2.) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rnd_cell = 100\n",
    "num_rnd_img = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the training data as a pandas dataframe'''\n",
    "directories = ['/home/garner1/Work/dataset/cellImages/training_augmented/Cancer',\n",
    "               '/home/garner1/Work/dataset/cellImages/training_augmented/Immuno',\n",
    "              '/home/garner1/Work/dataset/cellImages/training_augmented/Other']\n",
    "\n",
    "'''Box each nucleus'''\n",
    "cell_labels = []\n",
    "target_id = 0\n",
    "widths = []\n",
    "heights = []\n",
    "target = []\n",
    "for directory in directories:\n",
    "    target_id += 1\n",
    "    cell_id = 0\n",
    "    cellList = random.sample(os.listdir(directory), k=num_rnd_cell)\n",
    "    if directory == directories[0]: cellList_cancer = list(cellList)\n",
    "    if directory == directories[1]: cellList_immuno = list(cellList)\n",
    "    if directory == directories[2]: cellList_other = list(cellList)\n",
    "    for cell in cellList:\n",
    "        path = os.path.join(directory, cell)\n",
    "        cell_id += 1\n",
    "        imgList = random.sample(os.listdir(path), k=num_rnd_img) #sample images\n",
    "        if directory == directories[0]: imgList_cancer = list(imgList)\n",
    "        if directory == directories[1]: imgList_immuno = list(imgList)\n",
    "        if directory == directories[2]: imgList_other = list(imgList)\n",
    "        for img in imgList:\n",
    "            filename = os.path.join(path, img)\n",
    "            img = imageio.imread(filename)\n",
    "            rmin, rmax, cmin, cmax = bbox(img)\n",
    "            width = rmax-rmin\n",
    "            height = cmax-cmin\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "            target.append(target_id)    \n",
    "            cell_labels.append(cell_id)\n",
    "        \n",
    "            \n",
    "'''Resizing images to small boxes'''\n",
    "Mwidths = 60\n",
    "Mheights = 60\n",
    "images = []\n",
    "for directory in directories:\n",
    "    if directory == directories[0]: cellList = list(cellList_cancer)\n",
    "    if directory == directories[1]: cellList = list(cellList_immuno)\n",
    "    if directory == directories[2]: cellList = list(cellList_other)\n",
    "    for cell in cellList:\n",
    "        path = os.path.join(directory, cell)\n",
    "        if directory == directories[0]: imgList = list(imgList_cancer)\n",
    "        if directory == directories[1]: imgList = list(imgList_immuno)\n",
    "        if directory == directories[2]: imgList = list(imgList_other)\n",
    "        for img in imgList:\n",
    "            filename = os.path.join(path, img)\n",
    "            img = imageio.imread(filename)\n",
    "            rmin, rmax, cmin, cmax = bbox(img)\n",
    "            delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "            newimg = np.pad(img[rmin:rmax,cmin:cmax],((left,right),(top,bottom)),'constant', constant_values=(0))\n",
    "            images.append(newimg)\n",
    "            \n",
    "data = np.zeros((len(images),Mwidths*Mheights))\n",
    "for ind in range(len(images)):\n",
    "    data[ind,:] = images[ind].flatten() # from 2D arrays to 1D arrays\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3D embedding'''\n",
    "n_neighbors = 30  #this parameter affects the distinguishability between clusters, the higher the better, but it costs computationally\n",
    "%time embedding = umap.UMAP(n_neighbors=n_neighbors,min_dist=0.0,n_components=3,random_state=42).fit_transform(data) # do not include target together with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3D visualization of annotated data'''\n",
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "fig = go.Figure()\n",
    "size = 10\n",
    "names = ['cancer','immuno','other']\n",
    "for label in set(target):\n",
    "    labeled = [ind for ind in range(len(target)) if target[ind] == label]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=embedding[labeled,0],  # <-- Put your data instead\n",
    "        y=embedding[labeled,1],  # <-- Put your data instead\n",
    "        z=embedding[labeled,2],  # <-- Put your data instead\n",
    "        name=str(names[label-1]),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=label,size=2, opacity=0.5)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"Reduction in 3D \",title_font_size=30)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding,target,stratify=target,random_state=42)\n",
    "\n",
    "# Create a classifier\n",
    "# classifier = svm.SVC(gamma=0.001)\n",
    "classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(predicted, y_test)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Select images where prediction is different from expert annotation'''\n",
    "diff_index_list = [ind for ind in range(len(y_test)) if abs(predicted[ind]-y_test[ind])>0]\n",
    "\n",
    "List = []\n",
    "for j in diff_index_list:\n",
    "    [List.append(index) for index in range(len(embedding)) if all(embedding[index]-X_test[j]==0)]\n",
    "\n",
    "row_list = [List[ind] for ind in range(len(List)) if abs(predicted[ind]-y_test[ind])>0]\n",
    "data_selection = data[row_list,:]\n",
    "predicted_selection = [predicted[ind] for ind in range(len(List)) if abs(predicted[ind]-y_test[ind])>0]\n",
    "y_test_selection = [y_test[ind] for ind in range(len(List)) if abs(predicted[ind]-y_test[ind])>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(80,60)})\n",
    "\n",
    "num_of_examples = 2\n",
    "rnd = random.sample([ind for ind in range(len(predicted_selection))],k=num_of_examples)\n",
    "predicted_images = list([zip(data_selection, predicted_selection)[ind] for ind in rnd])\n",
    "for index, (image, label) in enumerate(predicted_images):\n",
    "    plt.subplot(2, num_of_examples, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape((Mwidths,Mheights)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('T: %i' % label,fontsize=100)\n",
    "    \n",
    "\n",
    "test_images_and_labels = list([zip(data_selection, y_test_selection)[ind] for ind in rnd])\n",
    "for index, (image, label) in enumerate(test_images_and_labels):\n",
    "    plt.subplot(2, num_of_examples, index + 1 + num_of_examples)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape((Mwidths,Mheights)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('P: %i' % label,fontsize=100)\n",
    "\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we explore unsupervised clustering over the reduced data points. Reducing to 2d seems not to be sufficient to distinguish the immuno and cancer clusters. In 3d they become easily distinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HDBSCAN clusters in 3D\n",
    "low min sample size seems to refuce unclustered data;\n",
    "larger min cluster size decrease cluster numbers\n",
    "PCA reduction might not be a good idea because shape space is non-linear and the linear reduction could distort distances and later clustering\n",
    "'''\n",
    "labels = hdbscan.HDBSCAN(min_samples=100,min_cluster_size=200).fit_predict(embedding)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "size = 1\n",
    "for cluster in set(labels):\n",
    "    clustered = (labels == cluster)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=embedding[clustered,0],  # <-- Put your data instead\n",
    "        y=embedding[clustered,1],  # <-- Put your data instead\n",
    "        z=embedding[clustered,2],  # <-- Put your data instead\n",
    "        name=\"cluster \"+str(cluster),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster+1,size=cluster+2, opacity=0.5)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"HDBSCAN clusters in 3D \",title_font_size=30)\n",
    "fig.show()\n",
    "##########\n",
    "clustered = (labels >= 0)\n",
    "print('The percentage of clustered data points is '+str(np.sum(clustered) *1.0/ data.shape[0]*100)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Classification report for unsupervised clustering'''\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding,labels,stratify=labels,random_state=42)\n",
    "\n",
    "# Create a classifier\n",
    "# classifier = svm.SVC(gamma=0.001)\n",
    "classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(predicted, y_test)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict unlabeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We can: \n",
    "1) first train the dimensionality reduction\n",
    "2) load the unlabeld dataset\n",
    "3) transform the unlabeled dataset\n",
    "4) classify\n",
    "5) Visualize\n",
    "6) Map cluster label on the field of view\n",
    "'''\n",
    "\n",
    "'''_1_'''\n",
    "n_neighbors = 30  #this parameter affects the distinguishability between clusters, the higher the better, but it costs computationally\n",
    "%time trans = umap.UMAP(n_neighbors=n_neighbors,min_dist=0.0,n_components=3,random_state=42).fit(data) # do not include target together with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''_2_'''\n",
    "num_rnd_cell = 1699\n",
    "num_rnd_img = 10\n",
    "target = []\n",
    "directory = '/home/garner1/Work/dataset/cellImages/image52/augmented'\n",
    "\n",
    "cell_labels = []\n",
    "images = []\n",
    "cell_id = 0\n",
    "count = 0\n",
    "total = 0\n",
    "imgLists = []\n",
    "cellList = random.sample(os.listdir(directory), k=num_rnd_cell)\n",
    "for cell in cellList:\n",
    "    cell_id += 1\n",
    "    path = os.path.join(directory, cell)\n",
    "    imgList = random.sample(os.listdir(path), k=num_rnd_img) #sample images\n",
    "    imgLists.append(imgList)\n",
    "    for img in imgList:\n",
    "        filename = os.path.join(path, img)\n",
    "        img = imageio.imread(filename)\n",
    "        rmin, rmax, cmin, cmax = bbox(img)\n",
    "        delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "        total += 1\n",
    "        if delta_w >= 0:\n",
    "            if delta_h >= 0:\n",
    "                top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "                left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "                newimg = np.pad(img[rmin:rmax,cmin:cmax],((left,right),(top,bottom)),'constant', constant_values=(0))\n",
    "                cell_labels.append(cell_id)\n",
    "                images.append(newimg)\n",
    "                \n",
    "            \n",
    "X_new = np.zeros((len(images),Mwidths*Mheights))\n",
    "for ind in range(len(images)):\n",
    "    X_new[ind,:] = images[ind].flatten() # from 2D arrays to 1D arrays\n",
    "\n",
    "print(X_new.shape)\n",
    "\n",
    "'''_3_'''\n",
    "%time new_embedding = trans.transform(X_new)\n",
    "'''_4_'''\n",
    "new_predicted = classifier.predict(new_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time new_embedding = umap.UMAP(n_neighbors=n_neighbors,min_dist=0.0,n_components=3,random_state=42).fit_transform(X_new) # do not include target together with data\n",
    "'''\n",
    "HDBSCAN clusters in 3D\n",
    "low min sample size seems to refuce unclustered data;\n",
    "larger min cluster size decrease cluster numbers\n",
    "PCA reduction might not be a good idea because shape space is non-linear and the linear reduction could distort distances and later clustering\n",
    "'''\n",
    "%time labels = hdbscan.HDBSCAN(min_samples=100,min_cluster_size=200).fit_predict(embedding)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "size = 1\n",
    "for cluster in set(labels):\n",
    "    clustered = (labels == cluster)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=embedding[clustered,0],  # <-- Put your data instead\n",
    "        y=embedding[clustered,1],  # <-- Put your data instead\n",
    "        z=embedding[clustered,2],  # <-- Put your data instead\n",
    "        name=\"cluster \"+str(cluster),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster+1,size=cluster+2, opacity=0.5)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"HDBSCAN clusters in 3D \",title_font_size=30)\n",
    "fig.show()\n",
    "##########\n",
    "clustered = (labels >= 0)\n",
    "print('The percentage of clustered data points is '+str(np.sum(clustered) *1.0/ data.shape[0]*100)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''_5_'''\n",
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "fig = go.Figure()\n",
    "for cluster in set(new_predicted):\n",
    "    clustered = (new_predicted == cluster)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=new_embedding[clustered,0],  # <-- Put your data instead\n",
    "        y=new_embedding[clustered,1],  # <-- Put your data instead\n",
    "        z=new_embedding[clustered,2],  # <-- Put your data instead\n",
    "        name=\"cluster \"+str(cluster),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster+1,size=5, opacity=0.5)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"Reduction in 3D \",title_font_size=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "def nochar(blabla):\n",
    "    all = string.maketrans('','')\n",
    "    nodigs = all.translate(all, string.digits)\n",
    "    return blabla.translate(all, nodigs)\n",
    "\n",
    "cell_ok = [-1]*len(cell_labels)\n",
    "ind = 0\n",
    "count_unique_cells = 0\n",
    "image_ids = []\n",
    "for cell in cellList:\n",
    "    path = os.path.join(directory, cell)\n",
    "    for img in imgLists[count_unique_cells]:\n",
    "        filename = os.path.join(path, img)\n",
    "        img = imageio.imread(filename)\n",
    "        rmin, rmax, cmin, cmax = bbox(img)\n",
    "        delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "        image_ids.append(int(nochar(filename.split('/')[-2]))+1) #number cells adding 1 because id start from 0 on disk storage\n",
    "        if delta_w >= 0:\n",
    "            if delta_h >= 0:\n",
    "                cell_ok[ind] = 1\n",
    "        ind += 1\n",
    "    count_unique_cells += 1\n",
    "\n",
    "List = zip(image_ids,list(new_predicted))\n",
    "\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "for k, v in List: \n",
    "    d[k].append(v) #group the cluster_id by cell_id\n",
    "\n",
    "from collections import Counter\n",
    "cluster_single_id = []\n",
    "for List in d.values():\n",
    "    c = Counter(List)\n",
    "    cluster_single_id.append(c.most_common(1)[0][0]) #these are sorted by cell_id value from 1 to numb_new_cells\n",
    "\n",
    "clustered = (np.asarray(cluster_single_id)>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/garner1/Work/dataset/cellImages/image52/properties.csv', 'r') as f:\n",
    "    properties = list(csv.reader(f, delimiter=','))\n",
    "properties = np.array(properties)\n",
    "\n",
    "fig = go.Figure()\n",
    "for cluster in list(set(new_predicted))[:3]:\n",
    "    clustered = (np.asarray(cluster_single_id)==cluster)\n",
    "    cell_selection = np.asarray([d.keys()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "    cluster_selection = np.asarray([d.values()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=properties[cell_selection,1].astype(np.float),  # <-- Put your data instead\n",
    "        y=properties[cell_selection,2].astype(np.float),  # <-- Put your data instead\n",
    "        name=\"cluster \"+str(cluster),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster+1,size=10, opacity=0.5)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"Reduction in 3D \",title_font_size=30,template=\"plotly_white\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = imageio.imread('/home/garner1/Work/dataset/cellImages/image52/iMS266_20190426_001.sub52.jpg')\n",
    "# sns.set(style='white', rc={'figure.figsize':(50,30)})\n",
    "# plt.scatter(properties[np.asarray(d.keys())[clustered],1].astype(np.float),\n",
    "#             properties[np.asarray(d.keys())[clustered],2].astype(np.float),\n",
    "#             c=np.asarray(cluster_id)[clustered],\n",
    "#             s=1000,\n",
    "#             cmap='Spectral',\n",
    "#             alpha=0.95);\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# for cluster in list(set(new_predicted))[:2]:\n",
    "#     print cluster\n",
    "#     clustered = (d.values() == cluster).flatten()\n",
    "#     cell_selection = np.asarray([d.keys()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "#     cluster_selection = np.asarray([d.values()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "#     print len(cell_selection)\n",
    "#     print len(cluster_selection.flatten())\n",
    "#     ax.scatter(properties[cell_selection,1].astype(np.float),\n",
    "#                 properties[cell_selection,2].astype(np.float),\n",
    "#                 c=cluster_selection.flatten()+1,\n",
    "#                 s=500,\n",
    "#                 cmap='Spectral',\n",
    "#                 alpha=0.75);\n",
    "    \n",
    "# plt.imshow(image,cmap='gray')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
