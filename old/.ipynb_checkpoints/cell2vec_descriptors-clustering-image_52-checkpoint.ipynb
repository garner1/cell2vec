{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptors seems to be too local and are not able to distinguish general properties able to cluster cells. The cluster that are generated are always randomly distributed in space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse import csc_matrix,coo_matrix\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN, KMeans, AffinityPropagation, MeanShift\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import kmapper as km\n",
    "from kmapper.cover import Cover\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "import networkx as nx\n",
    "from community import best_partition # this is not part of networkx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax    \n",
    "def embedding(data,dim):\n",
    "    projection = mapper.fit_transform(data, projection=umap.UMAP(n_components=dim, n_neighbors=200, \n",
    "                                             a=None, angular_rp_forest=False, b=None, init='spectral',\n",
    "                                           learning_rate=1.0, local_connectivity=1.0, metric='euclidean',\n",
    "                                           metric_kwds=None, min_dist=0.1, n_epochs=500,\n",
    "                                           negative_sample_rate=10, random_state=47,\n",
    "                                           repulsion_strength=1.0, set_op_mix_ratio=0.5, spread=0.25,\n",
    "                                           target_metric='categorical', target_metric_kwds=None,\n",
    "                                           target_n_neighbors=-1, target_weight=0.5, transform_queue_size=10.0,\n",
    "                                           transform_seed=42, verbose=False))\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the data'''\n",
    "widths = []\n",
    "heights = []\n",
    "target = []\n",
    "\n",
    "directory = '/home/garner1/Work/dataset/cellImages/Dataset_Image52/Nuclei_Image52'\n",
    "for img in os.listdir(directory):\n",
    "    filename = os.path.join(directory, img)\n",
    "    img = imageio.imread(filename)\n",
    "    rmin, rmax, cmin, cmax = bbox(img)\n",
    "    width = rmax-rmin\n",
    "    height = cmax-cmin\n",
    "    widths.append(width)\n",
    "    heights.append(height)\n",
    "    target.append(0)\n",
    "\n",
    "Mwidths = max(widths)\n",
    "Mheights = max(heights)\n",
    "\n",
    "'''Boxing all images homogeneously'''\n",
    "# nullimg = np.zeros(Mwidths,Mheights)\n",
    "images = []\n",
    "directory = '/home/garner1/Work/dataset/cellImages/Dataset_Image52/Nuclei_Image52'\n",
    "for img in os.listdir(directory):\n",
    "    filename = os.path.join(directory, img)\n",
    "    img = imageio.imread(filename)\n",
    "    rmin, rmax, cmin, cmax = bbox(img)\n",
    "    padwidth = int(Mwidths-(rmax-rmin))\n",
    "    padheight = int(Mheights-(cmax-cmin))\n",
    "    newimg = np.pad(img[rmin:rmax,cmin:cmax],((0,padwidth),(0,padheight)),'constant', constant_values=(0))\n",
    "    images.append(newimg)\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# defining feature extractor that we want to use\n",
    "extractor = cv2.ORB_create()\n",
    "\n",
    "def features(image, extractor):\n",
    "    keypoints, descriptors = extractor.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 10)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "\n",
    "img = np.pad(images[0], 50, pad_with, padder=0)   # pad the image with enough zeros to be process by ORB\n",
    "keypoints, descriptors = features(img, extractor)\n",
    "# data = np.dot(descriptors.T,descriptors).reshape((1,32*32))\n",
    "for img in images[1:]:\n",
    "    img = np.pad(img, 50, pad_with, padder=0)   # pad the image with enough zeros to be process by ORB\n",
    "    keypoints, descriptors = features(img, extractor)\n",
    "    \n",
    "    data = np.vstack((data,np.dot(descriptors.T,descriptors).reshape((1,32*32))))\n",
    "    \n",
    "#     keypoints_without_size = cv2.drawKeypoints(img, keypoints, keypoints_without_size, color = (0, 255, 0))\n",
    "#     keypoints_without_size = cv2.cvtColor(keypoints_without_size, cv2.COLOR_BGR2RGB)\n",
    "#     keypoints_without_size = cv2.cvtColor(keypoints_without_size, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#     keypoints_with_size = cv2.drawKeypoints(img, keypoints, keypoints_with_size, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "#     keypoints_with_size = cv2.cvtColor(keypoints_with_size, cv2.COLOR_BGR2RGB)\n",
    "#     keypoints_with_size = cv2.cvtColor(keypoints_with_size, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "#     # Display image with and without keypoints size\n",
    "#     fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "#     plots[0].set_title(\"Image\")\n",
    "#     plots[0].imshow(img, cmap='gray')\n",
    "\n",
    "#     plots[1].set_title(\"Train keypoints Without Size\")\n",
    "#     plots[1].imshow(keypoints_without_size, cmap='gray')\n",
    "    \n",
    "#     plots[2].set_title(\"Train keypoints With Size\")\n",
    "#     plots[2].imshow(keypoints_with_size, cmap='gray')\n",
    "\n",
    "\n",
    "    # Print the number of keypoints detected in the training image\n",
    "#     print(\"Number of Keypoints Detected In The Training Image: \", len(keypoints))    \n",
    "#     print(\"Number of Keypoints Detected In The Training Image: \", descriptors.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print data.shape\n",
    "data = PCA(n_components=100).fit_transform(data)\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2D visualization of annotated data'''\n",
    "d2_embedding = umap.UMAP(n_neighbors=10,min_dist=0.0,n_components=2,random_state=42).fit_transform(data)\n",
    "#####\n",
    "sns.set(style='white', rc={'figure.figsize':(10,8)})\n",
    "plt.scatter(d2_embedding[:, 0], d2_embedding[:, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HDBSCAN clusters in 2D\n",
    "low min sample size seems to refuce unclustered data;\n",
    "larger min cluster size decrease cluster numbers\n",
    "'''\n",
    "d2_labels = hdbscan.HDBSCAN(min_samples=3,min_cluster_size=30).fit_predict(d2_embedding)\n",
    "\n",
    "sns.set(style='white', rc={'figure.figsize':(10,8)})\n",
    "clustered = (d2_labels >= 0)\n",
    "plt.scatter(d2_embedding[~clustered, 0],\n",
    "            d2_embedding[~clustered, 1],\n",
    "            c=(0.5, 0.5, 0.5),\n",
    "            s=20,\n",
    "            alpha=0.5)\n",
    "plt.scatter(d2_embedding[clustered, 0],\n",
    "            d2_embedding[clustered, 1],\n",
    "            c=d2_labels[clustered],\n",
    "            s=20,\n",
    "            cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3D visualization of annotated data'''\n",
    "d3_embedding = umap.UMAP(n_neighbors=10,min_dist=0.0,n_components=3,random_state=42).fit_transform(data)\n",
    "######\n",
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()\n",
    "trace = go.Scatter3d(\n",
    "    x=d3_embedding[:,0],  # <-- Put your data instead\n",
    "    y=d3_embedding[:,1],  # <-- Put your data instead\n",
    "    z=d3_embedding[:,2],  # <-- Put your data instead\n",
    "    mode='markers',\n",
    "    marker=dict(color=1,size=3, opacity=1)\n",
    ")\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
    ")\n",
    "mydata = [trace]\n",
    "plot_figure = go.Figure(data=mydata, layout=layout)\n",
    "plotly.offline.iplot(plot_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "HDBSCAN clusters in 3D\n",
    "low min sample size seems to refuce unclustered data;\n",
    "larger min cluster size decrease cluster numbers\n",
    "PCA reduction might not be a good idea because shape space is non-linear and the linear reduction could distort distances and later clustering\n",
    "'''\n",
    "d3_labels = hdbscan.HDBSCAN(min_samples=3,min_cluster_size=50).fit_predict(d3_embedding)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "size = 2\n",
    "for cluster in set(d3_labels):\n",
    "    clustered = (d3_labels == cluster)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=d3_embedding[clustered,0],  # <-- Put your data instead\n",
    "        y=d3_embedding[clustered,1],  # <-- Put your data instead\n",
    "        z=d3_embedding[clustered,2],  # <-- Put your data instead\n",
    "        name=\"cluster \"+str(cluster),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster+1,size=size, opacity=1)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"HDBSCAN clusters in 3D\",\n",
    "                  title_font_size=30)\n",
    "fig.show()\n",
    "##########\n",
    "clustered = (d3_labels >= 0)\n",
    "print('The percentage of clustered data points is '+str(np.sum(clustered) *1.0/ data.shape[0]*100)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/garner1/Work/dataset/cellImages/Dataset_Image52/images'\n",
    "ind = 0\n",
    "image_cluster = []\n",
    "for img in os.listdir(directory):\n",
    "    filename = os.path.join(directory, img)\n",
    "    image_cluster.append((int(img.strip('.jpg')),d3_labels[ind]))\n",
    "    ind += 1\n",
    "    \n",
    "import operator\n",
    "image_cluster.sort(key = operator.itemgetter(0))\n",
    "ordered_d3_labels = np.array([cluster[1] for cluster in image_cluster])\n",
    "# print image_cluster[:20]\n",
    "# print ordered_d3_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/garner1/Work/dataset/cellImages/Dataset_Image52/properties.csv', 'r') as f:\n",
    "    properties = list(csv.reader(f, delimiter=','))\n",
    "properties = np.array(properties)\n",
    "\n",
    "image = imageio.imread('~/Work/dataset/cellImages/Dataset_Image52/iMS266_20190426_001.sub52.jpg')\n",
    "sns.set(style='white', rc={'figure.figsize':(50,30)})\n",
    "xy = properties[1:,1:3]\n",
    "labeled_cells = np.hstack((xy,ordered_d3_labels.reshape((xy.shape[0], 1))))\n",
    "\n",
    "plt.scatter(labeled_cells[clustered,0].astype(np.float),\n",
    "            labeled_cells[clustered,1].astype(np.float),\n",
    "            c=labeled_cells[clustered,2],\n",
    "            s=150,\n",
    "            cmap='Spectral',\n",
    "            alpha=0.75);\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get the node2vec representation of the centroid from each segmented cell. \n",
    "Use it together with the intensity array as input for the UMAP dimensionality reduction.\n",
    "Spatial contect + local intensity information'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"clusters.csv\", d3_labels.astype(int), delimiter=\",\", fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
