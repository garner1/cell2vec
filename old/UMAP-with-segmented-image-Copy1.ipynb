{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndarray\n",
    "\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse import csc_matrix,coo_matrix\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN, KMeans, AffinityPropagation, MeanShift\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax    \n",
    "def embedding(data,dim):\n",
    "    projection = mapper.fit_transform(data, projection=umap.UMAP(n_components=dim, n_neighbors=200, \n",
    "                                             a=None, angular_rp_forest=False, b=None, init='spectral',\n",
    "                                           learning_rate=1.0, local_connectivity=1.0, metric='euclidean',\n",
    "                                           metric_kwds=None, min_dist=0.1, n_epochs=500,\n",
    "                                           negative_sample_rate=10, random_state=47,\n",
    "                                           repulsion_strength=1.0, set_op_mix_ratio=0.5, spread=0.25,\n",
    "                                           target_metric='categorical', target_metric_kwds=None,\n",
    "                                           target_n_neighbors=-1, target_weight=0.5, transform_queue_size=10.0,\n",
    "                                           transform_seed=42, verbose=False))\n",
    "    return projection\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax    \n",
    "\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "\n",
    "def rotate_image(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2] # image shape has 3 dimensions\n",
    "    image_center = (width/2, height/2) # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "\n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0,0]) \n",
    "    abs_sin = abs(rotation_mat[0,1])\n",
    "\n",
    "    # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h))\n",
    "    return rotated_mat\n",
    "\n",
    "import math\n",
    "\n",
    "def round_up_to_even(f):\n",
    "    return int(math.ceil(f / 2.) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/garner1/Work/dataset/cellImages/image52/Nuclei_Image52'\n",
    "Mwidths = 60\n",
    "Mheights = 60\n",
    "images = []\n",
    "cell_id = []\n",
    "\n",
    "count = 1\n",
    "while count <= 1699: # use this loop form to make sure that cell_id are presersed\n",
    "    cell = str(count)+'.jpg'\n",
    "    filename = os.path.join(directory, cell)\n",
    "    img = imageio.imread(filename)\n",
    "    rmin, rmax, cmin, cmax = bbox(img)\n",
    "    delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "    if delta_w >= 0 and delta_h >= 0:\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "        newimg = np.pad(img[rmin:rmax,cmin:cmax],((left,right),(top,bottom)),'constant', constant_values=(0))\n",
    "        images.append(newimg)\n",
    "        cell_id.append(count)\n",
    "    else:\n",
    "        print(filename+' has a problem!')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/garner1/Work/dataset/cellImages/image52/properties.csv', 'r') as f:\n",
    "    properties = list(csv.reader(f, delimiter=','))\n",
    "XY = np.array(properties)[1:,1:3].astype(np.float)\n",
    "print(XY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(images),Mwidths*Mheights))\n",
    "for ind in range(len(images)):\n",
    "    X[ind,:] = images[ind].flatten() # from 2D arrays to 1D arrays\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2D embedding'''\n",
    "n_neighbors = 20\n",
    "\n",
    "'''\n",
    "Returns\n",
    "-------\n",
    "fuzzy_simplicial_set: coo_matrix\n",
    "A fuzzy simplicial set represented as a sparse matrix. The \n",
    "(i,j) entry of the matrix represents the membership strength of the\n",
    "1-simplex between the ith and jth sample points.\n",
    "'''\n",
    "mat_X = umap.umap_.fuzzy_simplicial_set(\n",
    "    X,\n",
    "    n_neighbors,\n",
    "    random_state=np.random.RandomState(seed=42),\n",
    "    metric='euclidean',\n",
    "    metric_kwds={},\n",
    "    knn_indices=None,\n",
    "    knn_dists=None,\n",
    "    angular=False,\n",
    "    set_op_mix_ratio=1.0,\n",
    "    local_connectivity=1.0,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "mat_XY = umap.umap_.fuzzy_simplicial_set(\n",
    "    XY,\n",
    "    n_neighbors,\n",
    "    random_state=np.random.RandomState(seed=42),\n",
    "    metric='euclidean',\n",
    "    metric_kwds={},\n",
    "    knn_indices=None,\n",
    "    knn_dists=None,\n",
    "    angular=False,\n",
    "    set_op_mix_ratio=1.0,\n",
    "    local_connectivity=1.0,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX = mat_X+min(mat_X.data)*np.ones(mat_X.shape)  # make mat dense otherwise hada is too sparse\n",
    "newXY = mat_XY+min(mat_XY.data)*np.ones(mat_XY.shape)\n",
    "hada = np.log10(np.multiply(newX,newXY))\n",
    "hada = hada-hada.min()\n",
    "# hada = mat_X+mat_XY\n",
    "# print(hada.shape,len(mat_X.data),len(mat_XY.data))\n",
    "print(hada.max(),hada.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hada.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import networkx as nx\n",
    "sns.set(style='white', rc={'figure.figsize':(50,50)})\n",
    "\n",
    "# G = nx.from_scipy_sparse_matrix(hada)\n",
    "G = nx.from_numpy_array(hada)\n",
    "eset = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] >= 4]\n",
    "weights = [d['weight'] for (u, v, d) in G.edges(data=True)]\n",
    "# weights = [5 for a_ in weights if a_ > 5 ]\n",
    "pos = XY\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos,alpha=0.9)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=eset,alpha=1.0, width=weights,edge_color='r')\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=esmall,width=6, alpha=0.5, edge_color='b', style='dashed')\n",
    "# nx.draw_networkx_labels(G, pos, font_size=20, font_family='sans-serif')\n",
    "plt.axis('off')\n",
    "\n",
    "img = cv2.imread('/home/garner1/Work/dataset/cellImages/image52/equalised_iMS266_20190426_001.sub52.tif', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "# Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
    "node2vec = Node2Vec(G, dimensions=2, walk_length=20, num_walks=200, workers=24)  # Use temp_folder for big graphs\n",
    "\n",
    "# Embed nodes\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `diemnsions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "\n",
    "embedding = np.asarray([model.wv[key] for idx, key in enumerate(model.wv.vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HDBSCAN clusters in 3D\n",
    "low min sample size seems to refuce unclustered data;\n",
    "larger min cluster size decrease cluster numbers\n",
    "PCA reduction might not be a good idea because shape space is non-linear and the linear reduction could distort distances and later clustering\n",
    "'''\n",
    "%time labels = hdbscan.HDBSCAN(min_samples=50,min_cluster_size=100).fit_predict(embedding)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "size = 1\n",
    "for cluster in list(set(labels))[:-1]:\n",
    "    clustered = (labels == cluster)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=embedding[clustered,0],  # <-- Put your data instead\n",
    "        y=embedding[clustered,1],  # <-- Put your data instead\n",
    "        z=embedding[clustered,2],  # <-- Put your data instead\n",
    "        name=\"cluster \"+str(cluster),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster+1,size=1, opacity=0.5)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"HDBSCAN clusters in 3D \",title_font_size=30)\n",
    "fig.show()\n",
    "##########\n",
    "clustered = (labels >= 0)\n",
    "print('The percentage of clustered data points is '+str(np.sum(clustered) *1.0/ X.shape[0]*100)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Classification report for unsupervised clustering'''\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding,labels,stratify=labels,random_state=42)\n",
    "\n",
    "# Create a classifier\n",
    "# classifier = svm.SVC(gamma=0.001)\n",
    "classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(predicted, y_test)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "def nochar(blabla):\n",
    "    all = string.maketrans('','')\n",
    "    nodigs = all.translate(all, string.digits)\n",
    "    return blabla.translate(all, nodigs)\n",
    "\n",
    "cell_ok = [-1]*len(cell_labels)\n",
    "ind = 0\n",
    "count_unique_cells = 0\n",
    "image_ids = []\n",
    "for cell in cellList:\n",
    "    path = os.path.join(directory, cell)\n",
    "    for img in imgLists[count_unique_cells]:\n",
    "        filename = os.path.join(path, img)\n",
    "        img = imageio.imread(filename)\n",
    "        rmin, rmax, cmin, cmax = bbox(img)\n",
    "        delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "        image_ids.append(int(nochar(filename.split('/')[-2]))+1) #number cells adding 1 because id start from 0 on disk storage\n",
    "        if delta_w >= 0:\n",
    "            if delta_h >= 0:\n",
    "                cell_ok[ind] = 1\n",
    "        ind += 1\n",
    "    count_unique_cells += 1\n",
    "\n",
    "List = zip(image_ids,list(labels))\n",
    "\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "for k, v in List: \n",
    "    d[k].append(v) #group the cluster_id by cell_id\n",
    "\n",
    "from collections import Counter\n",
    "cluster_single_id = []\n",
    "for List in d.values():\n",
    "    c = Counter(List)\n",
    "    cluster_single_id.append(c.most_common(1)[0][0]) #these are sorted by cell_id value from 1 to numb_new_cells\n",
    "\n",
    "clustered = (np.asarray(cluster_single_id)>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/home/garner1/Work/dataset/cellImages/image52/properties.csv', 'r') as f:\n",
    "    properties = list(csv.reader(f, delimiter=','))\n",
    "properties = np.array(properties)\n",
    "\n",
    "fig = go.Figure()\n",
    "print list(set(labels))[:-1]\n",
    "for cluster in list(set(labels))[:-1]:\n",
    "    clustered = (np.asarray(cluster_single_id)==cluster)\n",
    "    cell_selection = np.asarray([d.keys()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "    cluster_selection = np.asarray([d.values()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "    if len(cell_selection) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=properties[cell_selection,1].astype(np.float),  # <-- Put your data instead\n",
    "            y=properties[cell_selection,2].astype(np.float),  # <-- Put your data instead\n",
    "            name=\"cluster \"+str(cluster),\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=cluster+1,size=10, opacity=0.5)\n",
    "        ))\n",
    "fig.update_layout(title_text=\"Reduction in 3D \",title_font_size=30,template=\"plotly_white\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
