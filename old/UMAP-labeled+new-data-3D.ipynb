{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndarray\n",
    "\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse import csc_matrix,coo_matrix\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN, KMeans, AffinityPropagation, MeanShift\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import kmapper as km\n",
    "from kmapper.cover import Cover\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "import networkx as nx\n",
    "from community import best_partition # this is not part of networkx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax    \n",
    "def embedding(data,dim):\n",
    "    projection = mapper.fit_transform(data, projection=umap.UMAP(n_components=dim, n_neighbors=200, \n",
    "                                             a=None, angular_rp_forest=False, b=None, init='spectral',\n",
    "                                           learning_rate=1.0, local_connectivity=1.0, metric='euclidean',\n",
    "                                           metric_kwds=None, min_dist=0.1, n_epochs=500,\n",
    "                                           negative_sample_rate=10, random_state=47,\n",
    "                                           repulsion_strength=1.0, set_op_mix_ratio=0.5, spread=0.25,\n",
    "                                           target_metric='categorical', target_metric_kwds=None,\n",
    "                                           target_n_neighbors=-1, target_weight=0.5, transform_queue_size=10.0,\n",
    "                                           transform_seed=42, verbose=False))\n",
    "    return projection\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax    \n",
    "\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "\n",
    "def rotate_image(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2] # image shape has 3 dimensions\n",
    "    image_center = (width/2, height/2) # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "\n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0,0]) \n",
    "    abs_sin = abs(rotation_mat[0,1])\n",
    "\n",
    "    # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h))\n",
    "    return rotated_mat\n",
    "\n",
    "import math\n",
    "\n",
    "def round_up_to_even(f):\n",
    "    return int(math.ceil(f / 2.) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mwidths = 60 #width of the nucleus img\n",
    "Mheights = 60 #height in pixel of the nucleus image\n",
    "\n",
    "n_neighbors = 10 # in the UMAP algorithm\n",
    "\n",
    "num_rnd_Lcell = 200 # numb of labeled cells per type (max 200)\n",
    "num_rnd_Limg = 30 # numb of augmentation per labeled cell (max 720)\n",
    "\n",
    "num_rnd_Ncell = 600 # numb of new cells per type (max 200)\n",
    "num_rnd_Nimg = 30 # numb of augmentation per new cell (max 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the training data as a pandas dataframe'''\n",
    "directories = ['/home/garner1/Work/dataset/cellImages/training_augmented/Cancer',\n",
    "               '/home/garner1/Work/dataset/cellImages/training_augmented/Immuno',\n",
    "              '/home/garner1/Work/dataset/cellImages/training_augmented/Other']\n",
    "\n",
    "'''Box each nucleus'''\n",
    "cell_labels = []\n",
    "target_id = 0\n",
    "widths = []\n",
    "heights = []\n",
    "target = []\n",
    "for directory in directories:\n",
    "    target_id += 1\n",
    "    cell_id = 0\n",
    "    cellList = random.sample(os.listdir(directory), k=num_rnd_Lcell)\n",
    "    if directory == directories[0]: cellList_cancer = list(cellList)\n",
    "    if directory == directories[1]: cellList_immuno = list(cellList)\n",
    "    if directory == directories[2]: cellList_other = list(cellList)\n",
    "    for cell in cellList:\n",
    "        path = os.path.join(directory, cell)\n",
    "        cell_id += 1\n",
    "        imgList = random.sample(os.listdir(path), k=num_rnd_Limg) #sample images\n",
    "        if directory == directories[0]: imgList_cancer = list(imgList)\n",
    "        if directory == directories[1]: imgList_immuno = list(imgList)\n",
    "        if directory == directories[2]: imgList_other = list(imgList)\n",
    "        for img in imgList:\n",
    "            filename = os.path.join(path, img)\n",
    "            img = imageio.imread(filename)\n",
    "            rmin, rmax, cmin, cmax = bbox(img)\n",
    "            width = rmax-rmin\n",
    "            height = cmax-cmin\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "            target.append(target_id)    \n",
    "            cell_labels.append(cell_id)\n",
    "        \n",
    "            \n",
    "'''Resizing images to small boxes'''\n",
    "images = []\n",
    "for directory in directories:\n",
    "    if directory == directories[0]: cellList = list(cellList_cancer)\n",
    "    if directory == directories[1]: cellList = list(cellList_immuno)\n",
    "    if directory == directories[2]: cellList = list(cellList_other)\n",
    "    for cell in cellList:\n",
    "        path = os.path.join(directory, cell)\n",
    "        if directory == directories[0]: imgList = list(imgList_cancer)\n",
    "        if directory == directories[1]: imgList = list(imgList_immuno)\n",
    "        if directory == directories[2]: imgList = list(imgList_other)\n",
    "        for img in imgList:\n",
    "            filename = os.path.join(path, img)\n",
    "            img = imageio.imread(filename)\n",
    "            rmin, rmax, cmin, cmax = bbox(img)\n",
    "            delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "            newimg = np.pad(img[rmin:rmax,cmin:cmax],((left,right),(top,bottom)),'constant', constant_values=(0))\n",
    "            images.append(newimg)\n",
    "            \n",
    "X_labeled = np.zeros((len(images),Mwidths*Mheights))\n",
    "for ind in range(len(images)):\n",
    "    X_labeled[ind,:] = images[ind].flatten() # from 2D arrays to 1D arrays\n",
    "\n",
    "print(X_labeled.shape)\n",
    "\n",
    "'''_2_'''\n",
    "target = []\n",
    "directory = '/home/garner1/Work/dataset/cellImages/image52/augmented'\n",
    "cell_labels = []\n",
    "images = []\n",
    "cell_id = 0\n",
    "count = 0\n",
    "total = 0\n",
    "imgLists = []\n",
    "cellList = random.sample(os.listdir(directory), k=num_rnd_Ncell)\n",
    "for cell in cellList:\n",
    "    cell_id += 1\n",
    "    path = os.path.join(directory, cell)\n",
    "    imgList = random.sample(os.listdir(path), k=num_rnd_Nimg) #sample images\n",
    "    imgLists.append(imgList)\n",
    "    for img in imgList:\n",
    "        filename = os.path.join(path, img)\n",
    "        img = imageio.imread(filename)\n",
    "        rmin, rmax, cmin, cmax = bbox(img)\n",
    "        delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "        total += 1\n",
    "        if delta_w >= 0:\n",
    "            if delta_h >= 0:\n",
    "                top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "                left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "                newimg = np.pad(img[rmin:rmax,cmin:cmax],((left,right),(top,bottom)),'constant', constant_values=(0))\n",
    "                cell_labels.append(cell_id)\n",
    "                images.append(newimg)\n",
    "                \n",
    "            \n",
    "X_new = np.zeros((len(images),Mwidths*Mheights))\n",
    "for ind in range(len(images)):\n",
    "    X_new[ind,:] = images[ind].flatten() # from 2D arrays to 1D arrays\n",
    "\n",
    "print(X_new.shape)\n",
    "\n",
    "X = np.vstack((X_labeled,X_new))\n",
    "print(X.shape)\n",
    "\n",
    "# del X_labeled\n",
    "# del X_new\n",
    "# del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time embedding = umap.UMAP(n_neighbors=5,min_dist=0.0,n_components=3,random_state=42).fit_transform(X) # do not include target together with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HDBSCAN clusters in 3D\n",
    "low min sample size seems to refuce unclustered data;\n",
    "larger min cluster size decrease cluster numbers\n",
    "PCA reduction might not be a good idea because shape space is non-linear and the linear reduction could distort distances and later clustering\n",
    "'''\n",
    "%time labels = hdbscan.HDBSCAN(min_samples=200,min_cluster_size=200).fit_predict(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in range(num_rnd_Lcell*num_rnd_Limg): labels[ind] = -1 # hide labeled data\n",
    "# for ind in range(num_rnd_Lcell*num_rnd_Limg,num_rnd_Lcell*num_rnd_Limg+num_rnd_Ncell*num_rnd_Nimg): labels[ind] = -1 # hide new data\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "size = 1\n",
    "print set(labels)\n",
    "for cluster in list(set(labels))[:]:\n",
    "    clustered = (labels == cluster)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=embedding[clustered,0],  # <-- Put your data instead\n",
    "        y=embedding[clustered,1],  # <-- Put your data instead\n",
    "        z=embedding[clustered,2],  # <-- Put your data instead\n",
    "        name=\"cluster \"+str(cluster),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster+1,size=1, opacity=0.75)\n",
    "    ))\n",
    "fig.update_layout(title_text=\"HDBSCAN clusters in 3D \",title_font_size=30)\n",
    "fig.show()\n",
    "##########\n",
    "clustered = (labels >= 0)\n",
    "print('The percentage of clustered data points is '+str(np.sum(clustered) *1.0/ X.shape[0]*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Classification report for unsupervised clustering'''\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding,labels,stratify=labels,random_state=42)\n",
    "\n",
    "# Create a classifier\n",
    "# classifier = svm.SVC(gamma=0.001)\n",
    "classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(predicted, y_test)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "def nochar(blabla):\n",
    "    all = string.maketrans('','')\n",
    "    nodigs = all.translate(all, string.digits)\n",
    "    return blabla.translate(all, nodigs)\n",
    "\n",
    "cell_ok = [-1]*len(cell_labels)\n",
    "ind = 0\n",
    "count_unique_cells = 0\n",
    "image_ids = []\n",
    "for cell in cellList:\n",
    "    path = os.path.join(directory, cell)\n",
    "    for img in imgLists[count_unique_cells]:\n",
    "        filename = os.path.join(path, img)\n",
    "        img = imageio.imread(filename)\n",
    "        rmin, rmax, cmin, cmax = bbox(img)\n",
    "        delta_w, delta_h = Mwidths-(rmax-rmin), Mheights-(cmax-cmin)\n",
    "        image_ids.append(int(nochar(filename.split('/')[-2]))+1) #number cells adding 1 because id start from 0 on disk storage\n",
    "        if delta_w >= 0:\n",
    "            if delta_h >= 0:\n",
    "                cell_ok[ind] = 1\n",
    "        ind += 1\n",
    "    count_unique_cells += 1\n",
    "\n",
    "List = zip(image_ids,list(labels[-num_rnd_Ncell*num_rnd_Nimg:]))\n",
    "\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "for k, v in List: \n",
    "    d[k].append(v) #group the cluster_id by cell_id\n",
    "\n",
    "from collections import Counter\n",
    "cluster_single_id = []\n",
    "for List in d.values():\n",
    "    c = Counter(List)\n",
    "    cluster_single_id.append(c.most_common(1)[0][0]) #these are sorted by cell_id value from 1 to numb_new_cells\n",
    "\n",
    "clustered = (np.asarray(cluster_single_id)>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "with open('/home/garner1/Work/dataset/cellImages/image52/properties3.csv', 'r') as f:\n",
    "    properties = list(csv.reader(f, delimiter=','))\n",
    "properties = np.array(properties) # with header\n",
    "\n",
    "image = imageio.imread('/home/garner1/Work/dataset/cellImages/image52/iMS266_20190426_001.sub52.jpg')\n",
    "sns.set(style='white', rc={'figure.figsize':(50,30)})\n",
    "\n",
    "cmaps = ['b', 'r', 'g', 'y','c', 'k', 'w', 'm']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "print set(labels)\n",
    "for cluster in list(set(labels))[:-1]:\n",
    "    clustered = (np.asarray(cluster_single_id)==cluster)\n",
    "    cell_selection = np.asarray([d.keys()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "    cluster_selection = np.asarray([d.values()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "    if len(cell_selection) > 0:\n",
    "        circle_size = np.sqrt(np.asarray(properties[cell_selection,1].astype(np.float))*1.0/6.2)\n",
    "        circle_x = np.asarray(properties[cell_selection,2].astype(np.float))\n",
    "        circle_y = np.asarray(properties[cell_selection,3].astype(np.float))\n",
    "        for i in range(len(cell_selection)):\n",
    "            c = plt.Circle((circle_x[i],circle_y[i]), circle_size[i],color=cmaps[cluster],alpha=0.9)\n",
    "            ax.add_artist(c)\n",
    "\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(80,60)})\n",
    "\n",
    "num_of_examples = 8\n",
    "rnd = random.sample([ind for ind in range(X_new.shape[0])],k=num_of_examples)\n",
    "for index in range(num_of_examples):\n",
    "    plt.subplot(1, num_of_examples, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_new[rnd[index]].reshape((Mwidths,Mheights)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    \n",
    "    \n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('/home/garner1/Work/dataset/cellImages/image52/properties.csv', 'r') as f:\n",
    "#     properties = list(csv.reader(f, delimiter=','))\n",
    "# properties = np.array(properties) # with header\n",
    "\n",
    "# fig = go.Figure()\n",
    "# print list(set(labels))[:-1]\n",
    "# for cluster in list(set(labels))[:-1]:\n",
    "#     clustered = (np.asarray(cluster_single_id)==cluster)\n",
    "#     cell_selection = np.asarray([d.keys()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "#     cluster_selection = np.asarray([d.values()[ind] for ind in range(len(clustered)) if clustered[ind]])\n",
    "#     if len(cell_selection) > 0:\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=properties[cell_selection,1].astype(np.float),  # <-- Put your data instead\n",
    "#             y=properties[cell_selection,2].astype(np.float),  # <-- Put your data instead\n",
    "#             name=\"cluster \"+str(cluster),\n",
    "#             mode=\"markers\",\n",
    "#             marker=dict(color=cluster,size=cluster+5, opacity=0.5)\n",
    "#         ))\n",
    "# fig.update_layout(title_text=\"Reduction in 3D \",title_font_size=30,template=\"plotly_white\")\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
